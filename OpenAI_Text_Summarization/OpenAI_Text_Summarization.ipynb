{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing ICT & PRTSIR Ticket Text (summary + description) into OpenAI API\n",
    "- key needed\n",
    "- kernel = mypython\n",
    "- can either pass in pre-cleaned text, or uncleaned text (and clean after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Read recipe inputs\n",
    "input_dataset = dataiku.Dataset(\"PRTSIR_ICT_dataset_stacked\")\n",
    "df = input_dataset.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "prtsir_count = df['key'].str.startswith('PRTSIR').sum()\n",
    "ict_count = df['key'].str.startswith('ICT').sum()\n",
    "\n",
    "print(f\"Number of entries starting with 'PRTSIR': {prtsir_count}\")\n",
    "print(f\"Number of entries starting with 'ICT': {ict_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find average number of toens per row for each ticket type.\n",
    "#tokenize text for each ticket and calculate average\n",
    "def average_tokens_per_row(df, class_column, text_column, class_value):\n",
    "    class_rows = df[df[class_column] == class_value]\n",
    "    tokens_per_row = class_rows[text_column].apply(lambda x: len(x.split()))\n",
    "    avg_tokens = tokens_per_row.mean()\n",
    "    return avg_tokens\n",
    "\n",
    "avg_tokens_PRTSIR = average_tokens_per_row(df, 'label', 'Text', 1)\n",
    "avg_tokens_ICT = average_tokens_per_row(df, 'label', 'Text', 0)\n",
    "print(\"Average tokens per PRTSIR ticket:\", avg_tokens_PRTSIR)\n",
    "print(\"Average tokens per ICT ticket:\", avg_tokens_ICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of samples that can be processed per class\n",
    "#Given the total token budget, calculate the number of samples for each class\n",
    "#divide the available tokens by the sum of the average tokens for both classes.\n",
    "#Then, multiply the result by the average tokens for each class.\n",
    "\n",
    "total_budget = 18 * 1000  # Assuming $18 worth of tokens are equivalent to 18,000 tokens\n",
    "total_avg_tokens = avg_tokens_PRTSIR + avg_tokens_ICT\n",
    "\n",
    "samples_PRTSIR = int((total_budget / total_avg_tokens) * avg_tokens_PRTSIR)\n",
    "samples_ICT = int((total_budget / total_avg_tokens) * avg_tokens_ICT)\n",
    "print(\"Total tokens for PRTSIR:\", samples_PRTSIR)\n",
    "print(\"Total tokens for ICT:\",samples_ICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_PRTSIR = samples_PRTSIR / avg_tokens_PRTSIR\n",
    "rows_PRTSIR\n",
    "\n",
    "rows_ICT = samples_ICT / avg_tokens_ICT\n",
    "rows_ICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_class(df, class_column, class_value, n_samples):\n",
    "    class_rows = df[df[class_column] == class_value]\n",
    "    n_samples = min(n_samples, len(class_rows))  # Take the minimum of n_samples and the number of rows in the class\n",
    "    sampled_rows = class_rows.sample(n=n_samples, random_state=42)\n",
    "    return sampled_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Double Check math ##\n",
    "#Calculate the proportion of tokens for each class\n",
    "proportion_PRTSIR = avg_tokens_PRTSIR / total_avg_tokens\n",
    "proportion_ICT = avg_tokens_ICT / total_avg_tokens\n",
    "print(\"Proportion PRTSIR:\", proportion_PRTSIR)\n",
    "print(\"Proportion ICT:\", proportion_ICT)\n",
    "\n",
    "#Allocate tokens to each class based on the proportions\n",
    "tokens_PRTSIR = int(total_budget * proportion_PRTSIR)\n",
    "tokens_ICT = int(total_budget * proportion_ICT)\n",
    "print(\"tokens for PRTSIR:\", tokens_PRTSIR)\n",
    "print(\"tokens for ICT:\", tokens_ICT)\n",
    "\n",
    "#Calculate the number of rows for each class\n",
    "rows_PRTSIR = int(tokens_PRTSIR / avg_tokens_PRTSIR)\n",
    "rows_ICT = int(tokens_ICT / avg_tokens_ICT)\n",
    "print(\"num rows for PRTSIR:\", rows_PRTSIR)\n",
    "print(\"num rows for ICT:\", rows_ICT)\n",
    "\n",
    "#Sample the dataset using the calculated number of rows for each class\n",
    "sampled_PRTSIR = sample_class(df, 'label', 1, rows_PRTSIR)\n",
    "print(\"subset PRTSIR:\", len(sampled_PRTSIR))\n",
    "sampled_ICT = sample_class(df, 'label', 0, rows_ICT)\n",
    "print(\"subset ICT:\", len(sampled_ICT))\n",
    "\n",
    "sampled_df = pd.concat([sampled_PRTSIR, sampled_ICT]).reset_index(drop=True)\n",
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 1 row from each class with max length\n",
    "max_length_PRTSIR_index = sampled_df[sampled_df['label'] == 1]['Text'].str.len().idxmax()\n",
    "max_length_ICT_index = sampled_df[sampled_df['label'] == 0]['Text'].str.len().idxmax()\n",
    "\n",
    "sampled_df = sampled_df.drop([max_length_PRTSIR_index, max_length_ICT_index], axis=0).reset_index(drop=True)\n",
    "len(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row_to_drop_PRTSIR = sampled_df[sampled_df['label'] == 1].index[0]\n",
    "#row_to_drop_ICT = sampled_df[sampled_df['label'] == 0].index[0]\n",
    "\n",
    "#sampled_df = sampled_df.drop([row_to_drop_PRTSIR, row_to_drop_ICT], axis=0).reset_index(drop=True)\n",
    "#len(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total input tokens\n",
    "input_tokens = sampled_df['Text'].apply(lambda x: len(x.split()) + 1).sum()\n",
    "print(\"input_tokens:\", input_tokens)\n",
    "\n",
    "#Calculate the total summary tokens (from API output)\n",
    "summary_tokens = 50 * len(sampled_df)\n",
    "print(\"summary tokens:\", summary_tokens)\n",
    "\n",
    "#Calculate the total tokens used (input + output)\n",
    "total_tokens_used = input_tokens + summary_tokens\n",
    "print(\"total tokens used:\", total_tokens_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_PRTSIR = sample_class(df, 'label', 1, 5)\n",
    "#sampled_ICT = sample_class(df, 'label', 0, 5)\n",
    "\n",
    "#subset_df = pd.concat([sampled_PRTSIR, sampled_ICT]).reset_index(drop=True)\n",
    "#subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def summarize_text(text, api_key):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    max_tokens = 4000  # Maximum number of tokens allowed in one request\n",
    "    text_len = len(text.split())\n",
    "    num_batches = (text_len - 1) // max_tokens + 1  # Calculate the number of batches needed\n",
    "\n",
    "    summary = \"\"  # Initialize the summary\n",
    "\n",
    "    # Loop through the text in batches\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * max_tokens\n",
    "        end_idx = min((i + 1) * max_tokens, text_len)\n",
    "        text_batch = \" \".join(text.split()[start_idx:end_idx])\n",
    "\n",
    "        # Send the first 4000 tokens of the text batch to OpenAI API for summarization\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"text-davinci-002\",\n",
    "            prompt=f\"Please summarize the following text: {text_batch[:4000]}\",\n",
    "            max_tokens=100,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.5,\n",
    "        )\n",
    "\n",
    "        # Append the summary of the batch to the overall summary\n",
    "        batch_summary = response.choices[0].text.strip()\n",
    "        batch_summary = batch_summary.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "        summary += batch_summary\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in key and function\n",
    "api_key = .... #enter key here\n",
    "sampled_df['Text_Summarization'] = sampled_df['Text'].apply(lambda text: summarize_text(text, api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute recipe outputs from inputs\n",
    "# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n",
    "# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n",
    "\n",
    "# Write recipe outputs\n",
    "output_dataset = dataiku.Dataset(\"OpenAI_API_Text_Summarization\")\n",
    "output_dataset.write_with_schema(sampled_df)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_OpenAI_Text_Summarization",
  "createdOn": 1682716395162,
  "creationTag": {
   "lastModifiedBy": {
    "login": "vkb6bn"
   },
   "lastModifiedOn": 1682716395162,
   "versionNumber": 0
  },
  "creator": "vkb6bn",
  "customFields": {},
  "dkuGit": {
   "lastInteraction": 0
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "modifiedBy": "vkb6bn",
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
