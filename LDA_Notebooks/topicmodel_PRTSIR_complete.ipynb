{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with pyLDAvis\n",
    "-kernel = env mypython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "import os\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataiku.Dataset(\"PRTSIR_text_cleaned_cleaned\")\n",
    "df = data.get_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop missing values\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['description_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from summary_cleaned\n",
    "summary_corpus = df['summary_cleaned'].tolist()\n",
    "# Corpus as a list of text documents\n",
    "#summary_corpus = [' '.join(text.split()) for text in summary_corpus]\n",
    "summary_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract text from description_cleaned\n",
    "description_corpus = df['description_cleaned'].tolist()\n",
    "# Corpus as a list of text documents\n",
    "#description_corpus = [' '.join(text.split()) for text in description_corpus]\n",
    "description_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(description_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize & TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_corpus\n",
    "summary_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "summary_dtm_tf = summary_tf_vectorizer.fit_transform(summary_corpus)\n",
    "summary_tfidf_vectorizer = TfidfVectorizer(**summary_tf_vectorizer.get_params())\n",
    "summary_dtm_tfidf = summary_tfidf_vectorizer.fit_transform(summary_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_dtm_tf\n",
    "#summary_tfidf_vectorizer\n",
    "#summary_dtm_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description_corpus\n",
    "description_tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "description_dtm_tf = description_tf_vectorizer.fit_transform(description_corpus)\n",
    "description_tfidf_vectorizer = TfidfVectorizer(**description_tf_vectorizer.get_params())\n",
    "description_dtm_tfidf = description_tfidf_vectorizer.fit_transform(description_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description_dtm_tf\n",
    "#description_tfidf_vectorizer\n",
    "#description_dtm_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary_corpus\n",
    "#for TF DTM\n",
    "summary_lda_tf = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "summary_lda_tf.fit(summary_dtm_tf)\n",
    "# for TFIDF DTM\n",
    "#lda_tfidf = LatentDirichletAllocation(n_components=4, random_state=1)\n",
    "#lda_tfidf.fit(summary_dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#description_corpus\n",
    "#for TF DTM\n",
    "description_lda_tf = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "description_lda_tf.fit(description_dtm_tf)\n",
    "# for TFIDF DTM\n",
    "#lda_tfidf = LatentDirichletAllocation(n_components=4, random_state=1)\n",
    "#lda_tfidf.fit(description_dtm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vizualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the visualization for summary_corpus\n",
    "summary_prepared_data = pyLDAvis.sklearn.prepare(summary_lda_tf, summary_dtm_tf, summary_tf_vectorizer)\n",
    "summary_prepared_data.topic_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the visualization for description_corpus\n",
    "description_prepared_data = pyLDAvis.sklearn.prepare(description_lda_tf, description_dtm_tf, description_tf_vectorizer)\n",
    "description_prepared_data.topic_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary_corpus\n",
    "\n",
    "summary_prepared_data.topic_coordinates['x'] = summary_prepared_data.topic_coordinates['x'].apply(lambda x: x.real)\n",
    "summary_prepared_data.topic_coordinates['y'] = summary_prepared_data.topic_coordinates['y'].apply(lambda x: x.real)\n",
    "\n",
    "pyLDAvis.display(summary_prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description_corpus\n",
    "\n",
    "description_prepared_data.topic_coordinates['x'] = description_prepared_data.topic_coordinates['x'].apply(lambda x: x.real)\n",
    "description_prepared_data.topic_coordinates['y'] = description_prepared_data.topic_coordinates['y'].apply(lambda x: x.real)\n",
    "\n",
    "pyLDAvis.display(description_prepared_data)"
   ]
  }
 ],
 "metadata": {
  "associatedRecipe": "compute_topicmodel_PRTSIR_complete",
  "createdOn": 1679610425990,
  "creationTag": {
   "lastModifiedBy": {
    "login": "vkb6bn"
   },
   "lastModifiedOn": 1679610425990,
   "versionNumber": 0
  },
  "creator": "vkb6bn",
  "customFields": {},
  "dkuGit": {
   "lastInteraction": 0
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (env mypython)",
   "language": "python",
   "name": "py-dku-venv-mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "modifiedBy": "vkb6bn",
  "tags": [
   "recipe-editor"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
